AKANU IBIAM FEDERAL POLYTECHNIC, UNWANA
EBONYI STATE.
P.M.B 1007

SECOND ASSIGNMENT
ON

1:COMPARISON BETWEEN ARGUMENTATIVE INTELLIGENCE AND ARTIFICIAL INTELLIGENCE
2: HISTORY OF AI FROM 1940 TO DATE

WRITTEN BY
IGWE NWACHUKWU

APP NUMBER: APP/24/HND/01225

DEPARTMENT: COMPUTER SCIENCE
COURSE CODE: AIT 313
COURSE TITLE: ARTIFICATION INTELLIGENCE
LEVEL: HND1

DATE: 9Th MARCH 2025

Argumentative Intelligence (AIg) and Artificial Intelligence (AI) are two distinct but interrelated forms of intelligence. Below is a comparison of their key aspects:

Key Differences

1. Human vs. Machine: Argumentative intelligence is a human skill, while artificial intelligence is a machine capability.


2. Logical Reasoning vs. Pattern Recognition: Argumentative intelligence relies on structured reasoning, while AI relies on data patterns.


3. Emotion & Ethics: Humans consider emotions and ethics in arguments; AI lacks intrinsic ethical judgment.


4. Creativity & Adaptability: Humans can form original arguments dynamically, whereas AI-generated arguments are based on learned data.

Key Similarities

1. Both Aim to Improve Decision-Making: Both involve processing information to reach conclusions.


2. Both Can Be Used for Persuasion: AI-powered chatbots and recommendation systems can influence opinions, just like human arguments.


3. Both Depend on Data & Logic: While AI relies on statistical models, human argumentative intelligence is rooted in logical structures and evidence.


No 2:

The history of Artificial Intelligence (AI) from the 1940s to the present is marked by significant advancements in theory, computing power, and real-world applications. Below is a timeline of major milestones:

1940s–1950s: The Birth of AI Concepts

1943: Warren McCulloch and Walter Pitts propose the first mathematical model of artificial neurons, laying the foundation for neural networks.

1950: Alan Turing publishes "Computing Machinery and Intelligence," introducing the Turing Test to assess machine intelligence.

1956: The Dartmouth Conference, led by John McCarthy, Marvin Minsky, and others, formally establishes AI as a field of study. McCarthy coins the term Artificial Intelligence.


1960s: Early AI Programs and Challenges

AI research focuses on problem-solving and symbolic reasoning.

1966: ELIZA, an early chatbot developed by Joseph Weizenbaum, mimics human conversation.

The optimism of AI researchers leads to high expectations, but limited computing power hampers progress.


1970s: AI Winters and Expert Systems

AI experiences a funding decline (AI Winter) due to unrealistic expectations and slow progress.

1972: The Japanese government develops WABOT-1, the first humanoid robot.

Late 1970s: Expert systems (AI programs mimicking human expertise in specific domains) gain traction, such as MYCIN (used in medical diagnosis).


1980s: AI Resurgence with Expert Systems

AI funding increases due to the success of expert systems in industries.

1986: Geoffrey Hinton and others develop backpropagation for neural networks, improving AI learning.

AI experiences another setback in the late 1980s as expert systems prove costly and inflexible.


1990s: Machine Learning and Practical AI

1997: IBM's Deep Blue defeats world chess champion Garry Kasparov, marking AI’s capability in strategic games.

The rise of statistical AI and machine learning replaces rule-based systems, improving performance in speech and image recognition.


2000s: The Rise of Big Data and AI Applications

AI benefits from increased computing power and the explosion of internet data.

2006: Geoffrey Hinton revives deep learning, leading to breakthroughs in neural networks.

AI applications like Siri (2011) and Google’s self-driving car emerge.


2010s: AI Revolution with Deep Learning

2012: AlexNet, a deep learning model, wins the ImageNet competition, revolutionizing computer vision.

2016: Google's DeepMind AlphaGo defeats the world champion in Go, a complex board game.

AI becomes mainstream with Alexa, Google Assistant, and facial recognition systems.

2018–2019: AI surpasses human benchmarks in many NLP tasks, thanks to transformer models like BERT and GPT-2.


2020s–Present: Generative AI and AGI Aspirations

2020: OpenAI’s GPT-3 demonstrates human-like text generation.

2022: ChatGPT (GPT-3.5) and later GPT-4 revolutionize AI-driven conversations and content creation.

2023–2024: AI is integrated into various fields, including medicine, finance, art, and robotics.

AI safety, regulation, and ethical concerns become major global discussions as AGI (Artificial General Intelligence) research advances.
